{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 不使用tf model，創建一層RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 3\n",
    "n_neurons = 5\n",
    "\n",
    "X0 = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "X1 = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "\n",
    "Wx = tf.Variable(tf.random_normal(shape=[n_inputs, n_neurons]) ,dtype=tf.float32)\n",
    "Wy = tf.Variable(tf.random_normal(shape=[n_neurons,n_neurons]) ,dtype=tf.float32)\n",
    "b  = tf.Variable(tf.zeros([1, n_neurons]) ,dtype=tf.float32)\n",
    "\n",
    "Y0 = tf.tanh(tf.matmul(X0, Wx) + b)\n",
    "Y1 = tf.tanh(tf.matmul(Y0, Wy) + tf.matmul(X1,Wx) +b)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0_batch = np.array([\n",
    "    [0,1,2],\n",
    "    [3,4,5],\n",
    "    [6,7,8],\n",
    "    [9,0,1]\n",
    "])\n",
    "\n",
    "X1_batch = np.array([\n",
    "    [9,8,7],\n",
    "    [0,0,0],\n",
    "    [6,5,4],\n",
    "    [3,2,1]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.97787815  0.9995493  -0.40546837 -0.99443    -0.912637  ]\n",
      " [ 0.99767697  1.          0.9992052  -0.9999998  -0.99970406]\n",
      " [ 0.9997582   1.          1.         -1.         -0.99999905]\n",
      " [-0.99999964  0.99964935  1.          0.9999905  -0.5382053 ]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    Y0_val,Y1_val = sess.run([Y0, Y1], feed_dict={X0:X0_batch, X1:X1_batch})\n",
    "    print(Y0_val)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 通過時間靜態展開\n",
    "\n",
    "static_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0 = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "X1 = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "output_seqs, states = tf.contrib.rnn.static_rnn(\n",
    "    basic_cell, [X0,X1], dtype=tf.float32\n",
    ")\n",
    "\n",
    "Y0, Y1 = output_seqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  簡化流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "n_steps = 2 # 時間 t1, t2, ...\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "X_seqs = tf.unstack(tf.transpose(X, perm=[1,0,2]))\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "output_seqs, states = tf.contrib.rnn.static_rnn(\n",
    "    basic_cell,\n",
    "    X_seqs, \n",
    "    dtype=tf.float32\n",
    ")\n",
    "init = tf.global_variables_initializer()\n",
    "outputs = tf.transpose(tf.stack(output_seqs),perm=[1,0,2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (4,2,3)\n",
    "X_batch = [\n",
    "    #   t=0    t=1\n",
    "    [[0,1,2],[9,8,7]],\n",
    "    [[3,4,5],[0,0,0]],\n",
    "    [[6,7,8],[6,5,4]],\n",
    "    [[9,0,1],[3,2,1]]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.53172    -0.06129047  0.5259849   0.7461831   0.26974818]\n",
      "  [-1.          0.9851603   0.99629563  0.96319175 -0.999999  ]]\n",
      "\n",
      " [[-0.9992508   0.6339809   0.9485337   0.95923936 -0.9688956 ]\n",
      "  [-0.96497154  0.50815076  0.5328627  -0.6100401  -0.13661185]]\n",
      "\n",
      " [[-0.99999905  0.9150075   0.9955182   0.9940622  -0.999713  ]\n",
      "  [-0.9999999   0.9769739   0.9818434   0.22416943 -0.9999065 ]]\n",
      "\n",
      " [[-0.99967194 -0.2238567  -0.8682402   0.07244248 -0.9998998 ]\n",
      "  [-0.9947384   0.90954226  0.69278395 -0.82396156 -0.99886864]]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    outputs_val = outputs.eval(feed_dict={X: X_batch})\n",
    "    print(outputs_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 動態展開\n",
    "\n",
    "dynamic_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = tf.placeholder(tf.int32, [None]) # 迭代長度\n",
    "\n",
    "outputs, states = tf.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32, sequence_length=seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_batch = np.array([\n",
    "    [[0,1,2],[9,8,7]],\n",
    "    [[3,4,5],[0,0,0]], #這個batch的 t2 沒有資料， 補 0\n",
    "    [[6,7,8],[6,5,4]],\n",
    "    [[9,0,1],[3,2,1]]\n",
    "])\n",
    "\n",
    "seq_length_batch = np.array([2,1,2,2])\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.81785506  0.9999991  -0.99973786 -0.99928516  0.85950166]\n",
      " [-0.7025531   0.99975246 -0.80191535 -0.9969385   0.26512143]\n",
      " [-0.32151115  0.9998992  -0.99353904 -0.97632664  0.7759264 ]\n",
      " [-0.8950131   0.9917103  -0.979825   -0.7942098  -0.38231385]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    out_val, state_val = sess.run([outputs,states],feed_dict={X:X_batch,seq_length:seq_length_batch})\n",
    "    print(state_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.layers import fully_connected\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "n_steps   =  28\n",
    "n_inputs  =  28\n",
    "n_neurons = 150\n",
    "n_outputs =  10\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs]) # 輸入\n",
    "y = tf.placeholder(tf.int32  , [None])                    # labels\n",
    "\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "outputs, states = tf.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32)\n",
    "\n",
    "logits = fully_connected(states, n_outputs, activation_fn=None) # 最後一層, output\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                                                          labels=y, logits=logits)\n",
    "\n",
    "loss = tf.reduce_mean(xentropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-14-da9300976aa5>:4: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From c:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From c:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "# 加載數據\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\")\n",
    "X_test = mnist.test.images.reshape((-1, n_steps, n_inputs))\n",
    "y_test = mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train accuracy: 0.8933333 Test accuracy: 0.9106\n",
      "1 Train accuracy: 0.96 Test accuracy: 0.9462\n",
      "2 Train accuracy: 0.94 Test accuracy: 0.9592\n",
      "3 Train accuracy: 0.9533333 Test accuracy: 0.9562\n",
      "4 Train accuracy: 0.9866667 Test accuracy: 0.9692\n",
      "5 Train accuracy: 0.97333336 Test accuracy: 0.9643\n",
      "6 Train accuracy: 0.9866667 Test accuracy: 0.961\n",
      "7 Train accuracy: 0.97333336 Test accuracy: 0.9724\n",
      "8 Train accuracy: 0.9866667 Test accuracy: 0.9674\n",
      "9 Train accuracy: 0.9866667 Test accuracy: 0.9649\n",
      "10 Train accuracy: 0.99333334 Test accuracy: 0.9706\n",
      "11 Train accuracy: 0.9866667 Test accuracy: 0.9694\n",
      "12 Train accuracy: 0.97333336 Test accuracy: 0.9757\n",
      "13 Train accuracy: 0.9866667 Test accuracy: 0.9753\n",
      "14 Train accuracy: 0.99333334 Test accuracy: 0.973\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 15\n",
    "batch_size = 150\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples//batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            X_batch = X_batch.reshape((-1,n_steps, n_inputs))\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_test  = accuracy.eval(feed_dict={X: X_test,  y: y_test})\n",
    "        print(epoch, \"Train accuracy:\", acc_train, \"Test accuracy:\", acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 預測時間序列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_min, t_max = 0, 30\n",
    "resolution = 0.1\n",
    "\n",
    "def time_series(t):\n",
    "    return t * np.sin(t) / 3 + 2 * np.sin(t*5)\n",
    "\n",
    "def next_batch(batch_size, n_steps):\n",
    "    t0 = np.random.rand(batch_size, 1) * (t_max - t_min - n_steps * resolution)\n",
    "    Ts = t0 + np.arange(0., n_steps + 1) * resolution\n",
    "    ys = time_series(Ts)\n",
    "    return ys[:, :-1].reshape(-1, n_steps, 1), ys[:, 1:].reshape(-1, n_steps, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "n_steps   = 20\n",
    "n_inputs  = 1\n",
    "n_neurons = 100\n",
    "n_outputs = 1\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs ])\n",
    "y = tf.placeholder(tf.float32, [None, n_steps, n_outputs])\n",
    "cell = tf.contrib.rnn.OutputProjectionWrapper(  # rnn 10個(nodes)輸出，連接全連接層 輸出一個預測值\n",
    "    tf.contrib.rnn.BasicRNNCell(num_units=n_neurons, activation=tf.nn.relu),\n",
    "    output_size=n_outputs\n",
    ")\n",
    "outputs, states = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(outputs - y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \tMSE: 14.295551\n",
      "100 \tMSE: 0.45873547\n",
      "200 \tMSE: 0.16326381\n",
      "300 \tMSE: 0.07136521\n",
      "400 \tMSE: 0.053784274\n",
      "500 \tMSE: 0.04462791\n",
      "600 \tMSE: 0.05512355\n",
      "700 \tMSE: 0.049949203\n",
      "800 \tMSE: 0.049465798\n",
      "900 \tMSE: 0.043746725\n",
      "1000 \tMSE: 0.040598463\n",
      "1100 \tMSE: 0.04284016\n",
      "1200 \tMSE: 0.042445976\n",
      "1300 \tMSE: 0.04459831\n",
      "1400 \tMSE: 0.043287806\n",
      "1500 \tMSE: 0.045241427\n",
      "1600 \tMSE: 0.038770054\n",
      "1700 \tMSE: 0.04275372\n",
      "1800 \tMSE: 0.045583777\n",
      "1900 \tMSE: 0.043035455\n",
      "2000 \tMSE: 0.035891056\n",
      "2100 \tMSE: 0.04345268\n",
      "2200 \tMSE: 0.04104268\n",
      "2300 \tMSE: 0.05298567\n",
      "2400 \tMSE: 0.040818557\n",
      "2500 \tMSE: 0.03683746\n",
      "2600 \tMSE: 0.033581905\n",
      "2700 \tMSE: 0.041730445\n",
      "2800 \tMSE: 0.038496666\n",
      "2900 \tMSE: 0.033180237\n",
      "3000 \tMSE: 0.041560296\n",
      "3100 \tMSE: 0.042349033\n",
      "3200 \tMSE: 0.03794605\n",
      "3300 \tMSE: 0.03509926\n",
      "3400 \tMSE: 0.035193916\n",
      "3500 \tMSE: 0.03438435\n",
      "3600 \tMSE: 0.036999628\n",
      "3700 \tMSE: 0.041265767\n",
      "3800 \tMSE: 0.03916671\n",
      "3900 \tMSE: 0.040533196\n",
      "4000 \tMSE: 0.045616135\n",
      "4100 \tMSE: 0.038390335\n",
      "4200 \tMSE: 0.033646803\n",
      "4300 \tMSE: 0.033181913\n",
      "4400 \tMSE: 0.044789296\n",
      "4500 \tMSE: 0.036402732\n",
      "4600 \tMSE: 0.033685304\n",
      "4700 \tMSE: 0.0343959\n",
      "4800 \tMSE: 0.038633436\n",
      "4900 \tMSE: 0.036220577\n"
     ]
    }
   ],
   "source": [
    "n_iterations = 5000\n",
    "batch_size   = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    init.run()\n",
    "    for iteration in range(n_iterations):\n",
    "        X_batch, y_batch = next_batch(batch_size, n_steps)\n",
    "        sess.run(training_op,feed_dict={X:X_batch,y:y_batch})\n",
    "        if iteration%100 ==0:\n",
    "            mse = loss.eval(feed_dict={X:X_batch, y:y_batch})\n",
    "            print(iteration, \"\\tMSE:\",mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 't_instance' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-e4b957451641>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mX_new\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime_series\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt_instance\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_steps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mX_new\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 't_instance' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
